{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n",
    "\n",
    "1. See ph1-inmemory for cuda setup\n",
    "2. Install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (2.19.1)\n",
      "Requirement already satisfied: filelock in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (0.23.1)\n",
      "Requirement already satisfied: packaging in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\dev\\ai\\phi-fine-tuning\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# accessible large language models via k-bit quantization for PyTorch\n",
    "%pip install bitsandbytes\n",
    "# a library for easily accessing, sharing, and processing datasets for Audio, Computer Vision, and Natural Language Processing (NLP) tasks\n",
    "%pip install datasets\n",
    "# stands for Parameter-Efficient Fine-Tuning is a library for efficiently adapting large pre-trained models to various downstream applications without fine-tuning all of a modelâ€™s parameters because it is prohibitively costly\n",
    "%pip install peft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda_is_available? True\n",
      "Using: NVIDIA RTX A2000 Laptop GPU \n"
     ]
    }
   ],
   "source": [
    "# validate that Cuda is available\n",
    "import torch\n",
    "\n",
    "# print the cuda device name\n",
    "print(\"Cuda_is_available? {}\\nUsing: {} \".format(\n",
    "    torch.cuda.is_available(),\n",
    "    torch.cuda.get_device_name())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a helper function to print GPU utilization\n",
    "import GPUtil\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    \"\"\"Prints GPU usage using GPUtil.\"\"\"\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    for gpu in gpus:\n",
    "        print(f\"GPU {gpu.id}: {gpu.name}, Utilization: {gpu.load * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a dataset that we can use to teach the model about new data. There are many from Hugging face, and you can build your own. Here we will use the Guanaco dataset from Tim Dettmers.\n",
    "\n",
    "> This dataset is a subset of the Open Assistant dataset, which you can find here: https://huggingface.co/datasets/OpenAssistant/oasst1/tree/main\n",
    "> This subset of the data only contains the highest-rated paths in the conversation tree, with a total of 9,846 samples.\n",
    "\n",
    "* https://huggingface.co/datasets/timdettmers/openassistant-guanaco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimdettmers/openassistant-guanaco\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"timdettmers/openassistant-guanaco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "base_model_id = \"microsoft/phi-1\"\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "# this line of code initializes a tokenizer (AutoTokenizer) using pretrained weights specified by base_model_id.\n",
    "# The use_fast=True option indicates that it should use a faster tokenizer implementation if possible\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
